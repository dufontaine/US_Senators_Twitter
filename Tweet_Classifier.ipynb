{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "\n",
    "import re\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\") \n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function to read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ReadData():\n",
    "    address = 'C:/Users/dfontaine/OneDrive - Gogo LLC/TwitterProject/all_tweets.csv'\n",
    "    df = pd.read_csv(address, sep='`',encoding = \"utf-8\")\n",
    "    #remove retweets\n",
    "    df = df[df['retweeted']=='False']\n",
    "    #remove independents\n",
    "    df = df[(df['Party'] == 'Republican') | (df['Party'] == 'Democratic')]\n",
    "    df = df[['full_text','Party']]\n",
    "    df = df.reset_index(drop=True)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function to pre-process text (remove stop-words and stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocessing(doc, lower = True, stop_word = True, punctuation = True, word = True, stem = True, removeDigs = True, removeURLs = True): \n",
    "    ''' \n",
    "    doc: one single document (string)\n",
    "    lower: convert words to lowercase\n",
    "    punctuation: remove punctuation?????????????????????????????\n",
    "    word: whether we want to word tokenize or sentence tokenize \n",
    "    stem: whether we want to stem  \n",
    "    steps: tokenize -> remove stopwords and digits -> remove punctuation -> stem \n",
    "    ''' \n",
    "    if lower: \n",
    "        doc = doc.lower()\n",
    "    if removeURLs:\n",
    "        doc = re.sub('(http|ftp|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?','',doc)\n",
    "    #remove ambersand\n",
    "    doc = re.sub('\\&amp;','',doc)\n",
    "    if removeDigs:\n",
    "        doc = ''.join([i for i in doc if not i.isdigit()])\n",
    "    if word: \n",
    "        if punctuation: \n",
    "            from nltk.tokenize import RegexpTokenizer \n",
    "            tokenizer = RegexpTokenizer(r'\\w+') \n",
    "            tokens = tokenizer.tokenize(doc)    \n",
    "    else: \n",
    "        tokens = nltk.sent_tokenize(doc)   \n",
    "    if stop_word: \n",
    "        tokens = [i for i in tokens if i not in stopwords]   \n",
    "    if stem: \n",
    "        stems = [stemmer.stem(t) for t in tokens]\n",
    "    return stems "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function to get word count matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getCountMatrixfromdocs(df, maxDF=0.8, minDF=0.01, maxFeat=10000, maxGram=1):\n",
    "    labels = np.array(df['Party'].values.tolist())\n",
    "    doc = df['full_text'].values.tolist()     # Converts tweets column into list of tweets\n",
    "    count_vectorizer = CountVectorizer(max_df = maxDF, max_features = maxFeat, min_df = minDF, stop_words = None, tokenizer = preprocessing, ngram_range = (1,maxGram)) \n",
    "    count_matrix = count_vectorizer.fit_transform(doc) \n",
    "    count_matrix = pd.DataFrame(count_matrix.todense())\n",
    "    #add column names to CountMatrix\n",
    "    Terms = [pair[1] for pair in enumerate(count_vectorizer.get_feature_names())]\n",
    "    count_matrix.columns = Terms\n",
    "    \n",
    "    return(count_matrix, labels, count_vectorizer, Terms)\n",
    "\n",
    "\n",
    "#####################################################\n",
    "#CREATING COUNT MATRIX FROM A NEW TWEET\n",
    "#####################################################\n",
    "#a,b,c,d = getCountMatrixfromdocs(df)\n",
    "\n",
    "#abc = c\n",
    "#c.vocabulary = d\n",
    "\n",
    "#count_matrix = c.fit_transform(['Dustin has access to the aca in america as of yesterday'])\n",
    "#count_matrix = pd.DataFrame(count_matrix.todense())\n",
    "#Terms = [pair[1] for pair in enumerate(c.get_feature_names())]\n",
    "#count_matrix.columns = Terms\n",
    "#print(count_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function to fit and score Naive Bayes classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fitNBevaluate(X, y, cv_folds):\n",
    "    kf = KFold(n_splits=cv_folds)\n",
    "    acc = []\n",
    "    fOne = []\n",
    "    confMat = []\n",
    "    X = X.values\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        clf = MultinomialNB().fit(X_train, y_train)\n",
    "        predicted = clf.predict(X_test)\n",
    "\n",
    "        acc.append(metrics.accuracy_score(y_test,predicted))\n",
    "        fOne.append(metrics.f1_score(y_test, predicted, average='weighted'))\n",
    "        confMat.append(metrics.confusion_matrix(y_test,predicted, labels=['Republican','Democratic']))\n",
    "    return(acc,fOne, confMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function to fit and score Logistic classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fitLevaluate(X, y, cv_folds, CW=None):\n",
    "    kf = KFold(n_splits=cv_folds)\n",
    "    acc = []\n",
    "    fOne = []\n",
    "    confMat = []\n",
    "    X = X.values\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        clf = LogisticRegression(class_weight=CW).fit(X_train, y_train)\n",
    "        predicted = clf.predict(X_test)\n",
    "\n",
    "        acc.append(metrics.accuracy_score(y_test,predicted))\n",
    "        fOne.append(metrics.f1_score(y_test, predicted, average='weighted'))\n",
    "        confMat.append(metrics.confusion_matrix(y_test,predicted, labels=['Republican','Democratic']))\n",
    "    return(acc,fOne, confMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function to fit and score KNN classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fitKNNevaluate(X, y, cv_folds, K=1):\n",
    "    kf = KFold(n_splits=cv_folds)\n",
    "    acc = []\n",
    "    fOne = []\n",
    "    confMat = []\n",
    "    X = X.values\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        clf = KNeighborsClassifier(n_neighbors=K).fit(X_train, y_train)\n",
    "        predicted = clf.predict(X_test)\n",
    "\n",
    "        acc.append(metrics.accuracy_score(y_test,predicted))\n",
    "        fOne.append(metrics.f1_score(y_test, predicted, average='weighted'))\n",
    "        confMat.append(metrics.confusion_matrix(y_test,predicted, labels=['Republican','Democratic']))\n",
    "    return(acc,fOne, confMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function to fit and score TREE classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fitTREEevaluate(X, y, cv_folds):\n",
    "    kf = KFold(n_splits=cv_folds)\n",
    "    acc = []\n",
    "    fOne = []\n",
    "    confMat = []\n",
    "    X2 = X\n",
    "    X = X.values\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        clf = tree.DecisionTreeClassifier().fit(X_train, y_train) #previously had max_depth=20\n",
    "        predicted = clf.predict(X_test)\n",
    "        \n",
    "        #with open(\"xTREExTESTx.dot\", 'w') as f:\n",
    "        #    f = tree.export_graphviz(clf, out_file=f, \n",
    "        #                 feature_names=X2.columns,  \n",
    "        #                 class_names=['Both','IFC','IFE'],  \n",
    "        #                 filled=True, rounded=True,  \n",
    "        #                 special_characters=True)\n",
    "        #dot -Tpdf xTREExTESTx.dot -o outfile.pdf\n",
    "        #^ run this in command prompt\n",
    "\n",
    "        acc.append(metrics.accuracy_score(y_test,predicted))\n",
    "        fOne.append(metrics.f1_score(y_test, predicted, average='weighted'))\n",
    "        confMat.append(metrics.confusion_matrix(y_test,predicted, labels=['Republican','Democratic']))\n",
    "    return(acc,fOne, confMat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data...\n",
      "done\n",
      "fitting model \n",
      " nGram= 1\n",
      " minDF= 0.001\n",
      " NB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dfontaine\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model \n",
      " nGram= 1\n",
      " minDF= 0.001\n",
      " LOG-un\n",
      "fitting model \n",
      " nGram= 1\n",
      " minDF= 0.001\n",
      " LOG-bal\n",
      "fitting model \n",
      " nGram= 1\n",
      " minDF= 0.001\n",
      " TREE\n",
      "fitting model \n",
      " nGram= 1\n",
      " minDF= 0.001\n",
      " KNN5\n",
      "fitting model \n",
      " nGram= 1\n",
      " minDF= 0.006\n",
      " NB\n",
      "fitting model \n",
      " nGram= 1\n",
      " minDF= 0.006\n",
      " LOG-un\n",
      "fitting model \n",
      " nGram= 1\n",
      " minDF= 0.006\n",
      " LOG-bal\n",
      "fitting model \n",
      " nGram= 1\n",
      " minDF= 0.006\n",
      " TREE\n",
      "fitting model \n",
      " nGram= 1\n",
      " minDF= 0.006\n",
      " KNN5\n",
      "fitting model \n",
      " nGram= 1\n",
      " minDF= 0.011\n",
      " NB\n",
      "fitting model \n",
      " nGram= 1\n",
      " minDF= 0.011\n",
      " LOG-un\n",
      "fitting model \n",
      " nGram= 1\n",
      " minDF= 0.011\n",
      " LOG-bal\n",
      "fitting model \n",
      " nGram= 1\n",
      " minDF= 0.011\n",
      " TREE\n",
      "fitting model \n",
      " nGram= 1\n",
      " minDF= 0.011\n",
      " KNN5\n",
      "fitting model \n",
      " nGram= 1\n",
      " minDF= 0.016\n",
      " NB\n",
      "fitting model \n",
      " nGram= 1\n",
      " minDF= 0.016\n",
      " LOG-un\n",
      "fitting model \n",
      " nGram= 1\n",
      " minDF= 0.016\n",
      " LOG-bal\n",
      "fitting model \n",
      " nGram= 1\n",
      " minDF= 0.016\n",
      " TREE\n",
      "fitting model \n",
      " nGram= 1\n",
      " minDF= 0.016\n",
      " KNN5\n",
      "fitting model \n",
      " nGram= 1\n",
      " minDF= 0.021\n",
      " NB\n",
      "fitting model \n",
      " nGram= 1\n",
      " minDF= 0.021\n",
      " LOG-un\n",
      "fitting model \n",
      " nGram= 1\n",
      " minDF= 0.021\n",
      " LOG-bal\n",
      "fitting model \n",
      " nGram= 1\n",
      " minDF= 0.021\n",
      " TREE\n",
      "fitting model \n",
      " nGram= 1\n",
      " minDF= 0.021\n",
      " KNN5\n",
      "fitting model \n",
      " nGram= 2\n",
      " minDF= 0.001\n",
      " NB\n",
      "fitting model \n",
      " nGram= 2\n",
      " minDF= 0.001\n",
      " LOG-un\n",
      "fitting model \n",
      " nGram= 2\n",
      " minDF= 0.001\n",
      " LOG-bal\n",
      "fitting model \n",
      " nGram= 2\n",
      " minDF= 0.001\n",
      " TREE\n",
      "fitting model \n",
      " nGram= 2\n",
      " minDF= 0.001\n",
      " KNN5\n",
      "fitting model \n",
      " nGram= 2\n",
      " minDF= 0.006\n",
      " NB\n",
      "fitting model \n",
      " nGram= 2\n",
      " minDF= 0.006\n",
      " LOG-un\n",
      "fitting model \n",
      " nGram= 2\n",
      " minDF= 0.006\n",
      " LOG-bal\n",
      "fitting model \n",
      " nGram= 2\n",
      " minDF= 0.006\n",
      " TREE\n",
      "fitting model \n",
      " nGram= 2\n",
      " minDF= 0.006\n",
      " KNN5\n",
      "fitting model \n",
      " nGram= 2\n",
      " minDF= 0.011\n",
      " NB\n",
      "fitting model \n",
      " nGram= 2\n",
      " minDF= 0.011\n",
      " LOG-un\n",
      "fitting model \n",
      " nGram= 2\n",
      " minDF= 0.011\n",
      " LOG-bal\n",
      "fitting model \n",
      " nGram= 2\n",
      " minDF= 0.011\n",
      " TREE\n",
      "fitting model \n",
      " nGram= 2\n",
      " minDF= 0.011\n",
      " KNN5\n",
      "fitting model \n",
      " nGram= 2\n",
      " minDF= 0.016\n",
      " NB\n",
      "fitting model \n",
      " nGram= 2\n",
      " minDF= 0.016\n",
      " LOG-un\n",
      "fitting model \n",
      " nGram= 2\n",
      " minDF= 0.016\n",
      " LOG-bal\n",
      "fitting model \n",
      " nGram= 2\n",
      " minDF= 0.016\n",
      " TREE\n",
      "fitting model \n",
      " nGram= 2\n",
      " minDF= 0.016\n",
      " KNN5\n",
      "fitting model \n",
      " nGram= 2\n",
      " minDF= 0.021\n",
      " NB\n",
      "fitting model \n",
      " nGram= 2\n",
      " minDF= 0.021\n",
      " LOG-un\n",
      "fitting model \n",
      " nGram= 2\n",
      " minDF= 0.021\n",
      " LOG-bal\n",
      "fitting model \n",
      " nGram= 2\n",
      " minDF= 0.021\n",
      " TREE\n",
      "fitting model \n",
      " nGram= 2\n",
      " minDF= 0.021\n",
      " KNN5\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "#read data\n",
    "print('reading data...')\n",
    "df = ReadData()\n",
    "print('done')\n",
    "\n",
    "#test different models\n",
    "modList = []\n",
    "acc_all = []\n",
    "fOne_all = []\n",
    "conMat_all = []\n",
    "for i in range(1,3): #maxGram\n",
    "    for j in np.arange(0.001,0.026,0.005): #Min Doc Freq for words\n",
    "        curMODstr = '\\n nGram= ' + str(i) + '\\n minDF= ' + str(j) + '\\n NB'\n",
    "        print('fitting model '+curMODstr)\n",
    "        modList.append(curMODstr)\n",
    "        X, y, CountMatrix_vectorizer, doc = getCountMatrixfromdocs(df, maxDF=0.8, minDF=j, maxFeat=10000, maxGram=i)\n",
    "        acc, fOne, conMat = fitNBevaluate(X, y, cv_folds=10)\n",
    "        acc_all.append(acc)\n",
    "        fOne_all.append(fOne)\n",
    "        conMat_all.append(conMat)\n",
    "\n",
    "        curMODstr = '\\n nGram= ' + str(i) + '\\n minDF= ' + str(j) + '\\n LOG-un'\n",
    "        print('fitting model '+curMODstr)\n",
    "        modList.append(curMODstr)\n",
    "        acc, fOne, conMat = fitLevaluate(X, y, cv_folds=10)\n",
    "        acc_all.append(acc)\n",
    "        fOne_all.append(fOne)\n",
    "        conMat_all.append(conMat)\n",
    "\n",
    "        curMODstr = '\\n nGram= ' + str(i) + '\\n minDF= ' + str(j) + '\\n LOG-bal'\n",
    "        print('fitting model '+curMODstr)\n",
    "        modList.append(curMODstr)\n",
    "        acc2, fOne2, conMat2 = fitLevaluate(X, y, cv_folds=10, CW='balanced')\n",
    "        acc_all.append(acc2)\n",
    "        fOne_all.append(fOne2)\n",
    "        conMat_all.append(conMat2)\n",
    "            \n",
    "        curMODstr ='\\n nGram= ' + str(i) + '\\n minDF= ' + str(j) + '\\n TREE'\n",
    "        print('fitting model '+curMODstr)\n",
    "        modList.append(curMODstr)\n",
    "        acc2, fOne2, conMat2 = fitTREEevaluate(X, y, cv_folds=10)\n",
    "        acc_all.append(acc2)\n",
    "        fOne_all.append(fOne2)\n",
    "        conMat_all.append(conMat2)\n",
    "\n",
    "        for k in range(5,6):\n",
    "            curMODstr = '\\n nGram= ' + str(i) + '\\n minDF= ' + str(j) + '\\n KNN'+str(k)\n",
    "            print('fitting model '+curMODstr)\n",
    "            modList.append(curMODstr)\n",
    "            acc, fOne, conMat = fitKNNevaluate(X, y, cv_folds=10, K=k)\n",
    "            acc_all.append(acc)\n",
    "            fOne_all.append(fOne)\n",
    "            conMat_all.append(conMat)\n",
    "            \n",
    "print('DONE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dfontaine\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.711012575877\n"
     ]
    }
   ],
   "source": [
    "modList = []\n",
    "acc_all = []\n",
    "fOne_all = []\n",
    "conMat_all = []\n",
    "\n",
    "curMODstr = 'L'\n",
    "modList.append(curMODstr)\n",
    "X, y, count_vectorizer, terms = getCountMatrixfromdocs(df, maxDF=0.8, minDF=.001, maxFeat=10000, maxGram=1)\n",
    "\n",
    "print('fitting model '+curMODstr)\n",
    "acc2, fOne2, conMat2 = fitLevaluate(X, y, cv_folds=10)\n",
    "acc_all.append(acc2)\n",
    "fOne_all.append(fOne2)\n",
    "conMat_all.append(conMat2)\n",
    "\n",
    "print(np.mean(acc2))\n",
    "\n",
    "#makePlot(data=acc_all, labelz=modList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 492,  270],\n",
       "       [ 548, 2451]])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conMat2[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for i in [1,2,3,4,5]:\n",
    "    if i == 3: continue\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
